{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn.python.ops import rnn, rnn_cell\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 13, frames = 25):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            #print fn\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            #print fn\n",
    "            #print fn.split('/')[5].split('-')[0]\n",
    "            label = fn.split('/')[5].split('-')[0]\n",
    "            if(label=='n'):\n",
    "                label=0\n",
    "            if(label=='sp'):\n",
    "                label=1\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                    mfccs.append(mfcc)\n",
    "                    for ho in range(0,frames):\n",
    "                        labels.append(label)         \n",
    "    features = np.asarray(mfccs).reshape(len(mfccs)*frames,bands)\n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parent_dir = '/home/samim/audiotrainingset/'\n",
    "\n",
    "tr_sub_dirs = ['/home/samim/audiotrainingset/training/']\n",
    "tr_features,tr_labels = extract_features(parent_dir,tr_sub_dirs)\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_sub_dirs = ['/home/samim/audiotrainingset/testing/']\n",
    "ts_features,ts_labels = extract_features(parent_dir,ts_sub_dirs)\n",
    "ts_labels = one_hot_encode(ts_labels)\n",
    "ts_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-3a08772dbf28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'length'"
     ]
    }
   ],
   "source": [
    "np.length(ts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for a singledata/audio sample\n",
    "parent_dir = '/home/samim/audiotrainingset/'\n",
    "single_dirs = ['/home/samim/audiotrainingset/mydata/']\n",
    "single_features,single_labels = extract_features(parent_dir,single_dirs)\n",
    "single_labels = one_hot_encode(single_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a8b1cb3d395e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the mfcc and labels into a pickle file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"tr_features.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtr_labels\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"tr_labels.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mts_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"ts_features.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the mfcc and labels into a pickle file.\n",
    "import cPickle as pickle\n",
    "pickle.dump( tr_features, open( \"tr_features.p\", \"wb\" ) )\n",
    "pickle.dump( tr_labels , open( \"tr_labels.p\", \"wb\" ) )\n",
    "pickle.dump( ts_features, open( \"ts_features.p\", \"wb\" ) )\n",
    "pickle.dump( ts_labels , open( \"ts_labels.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the  mfcc and labels back from the pickle file.\n",
    "import cPickle as pickle\n",
    "tr_features = pickle.load( open( \"tr_features.p\", \"rb\" ) )\n",
    "tr_labels = pickle.load( open( \"tr_labels.p\", \"rb\" ) )\n",
    "ts_features = pickle.load( open( \"ts_features.p\", \"rb\" ) )\n",
    "ts_labels = pickle.load( open( \"ts_labels.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40450, 13)\n",
      "(2700, 13)\n",
      "(40450, 2)\n",
      "(2700, 2)\n",
      "(10700, 13)\n",
      "(10700, 2)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(tr_features)\n",
    "print np.shape(ts_features)\n",
    "print np.shape(tr_labels)\n",
    "print np.shape(ts_labels)\n",
    "print np.shape(single_features)\n",
    "print np.shape(single_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  28.15841643  135.38226361  -57.07620374 ...,    1.56619996\n",
      "    -7.09202049  -31.50583012]\n",
      " [  24.09893125  137.90576327 -114.65619221 ...,    2.76746728\n",
      "   -13.80398321  -40.81468196]\n",
      " [ -88.58701285   93.49443242 -217.68395476 ...,   -7.49118347\n",
      "     4.11981853  -29.8041856 ]\n",
      " ..., \n",
      " [-365.26763342  221.46193591  -75.21476963 ...,  -32.07783477\n",
      "    -9.96381627  -12.28702448]\n",
      " [-301.75540683  183.0349974   -67.3393457  ...,  -32.55723463\n",
      "   -17.17785367   -1.30824554]\n",
      " [-277.44060537  159.09760949  -56.63679668 ...,  -33.11707145\n",
      "   -18.06695419    3.47183371]]\n",
      "[[ -1.63014319e+02   1.19716560e+02  -3.01664719e+01 ...,  -1.20770038e+00\n",
      "   -1.23764010e+01   8.25812088e+00]\n",
      " [ -2.31086079e+02   1.19702416e+02  -3.01851377e+01 ...,  -1.23331644e+00\n",
      "   -1.23827580e+01   8.28874059e+00]\n",
      " [ -8.50596566e+02  -2.72998029e+00  -2.16464621e+00 ...,  -3.93243938e+00\n",
      "   -2.87728434e-01   4.15265579e+00]\n",
      " ..., \n",
      " [ -3.56537802e+02   1.85095644e+02   1.66250130e+01 ...,  -2.10503693e+01\n",
      "   -3.35758906e+00  -1.53366575e+01]\n",
      " [ -3.35524730e+02   2.07649195e+02   2.16151307e+01 ...,  -2.08813629e+01\n",
      "   -9.28566134e+00  -9.51389744e+00]\n",
      " [ -3.35413126e+02   2.16570887e+02   3.44433576e+01 ...,  -1.57767232e+01\n",
      "   -7.31958215e+00  -4.70067242e+00]]\n"
     ]
    }
   ],
   "source": [
    "print tr_features\n",
    "#print ts_features\n",
    "print single_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-255.45413705,  198.71187532,  -79.96107757, ...,   -1.44079077,\n",
       "          10.4169873 ,  -16.62076688],\n",
       "       [-184.36090782,  216.22932919, -113.54443459, ...,  -12.52371133,\n",
       "          14.98350096,  -22.34927891],\n",
       "       [-151.1976834 ,  225.74471473, -124.068053  , ...,  -17.00080968,\n",
       "          16.66690704,  -22.87408242],\n",
       "       ..., \n",
       "       [-192.58763491,  184.79552786, -163.98130449, ...,   -1.12378932,\n",
       "          37.2343807 ,  -21.0776174 ],\n",
       "       [-160.48657688,  151.70822638, -140.85556959, ...,   -1.75234939,\n",
       "          35.67985213,  -15.21926118],\n",
       "       [-162.64160268,  143.59671082, -105.44417801, ...,    0.28057274,\n",
       "          31.427609  ,  -12.10403295]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax_2:0\", shape=(10700, 2), dtype=float64)\n",
      "Tensor(\"Softmax_1:0\", shape=(175, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "mfcc_size=13\n",
    "num_labels=2\n",
    "batch_size = 1128\n",
    "hidden_size = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, mfcc_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    #tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(ts_features)\n",
    "    tf_test_dataset2 = tf.constant(single_features)\n",
    "    # Variables.\n",
    "    W1 = tf.Variable(tf.truncated_normal([mfcc_size, hidden_size]))\n",
    "    b1 = tf.Variable(tf.zeros([hidden_size]))\n",
    "\n",
    "    W2 = tf.Variable(tf.truncated_normal([hidden_size, num_labels]))\n",
    "    b2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    #W1=tf.cast(W1, tf.float64)\n",
    "    #b1=tf.cast(b1, tf.float64)\n",
    "    #W2=tf.cast(W2, tf.float64)\n",
    "    #b2=tf.cast(b2, tf.float64)\n",
    "    # Training computation.\n",
    "    y1 = tf.nn.relu( tf.matmul(tf_train_dataset, W1) + b1 )\n",
    "    logits = tf.matmul(y1, W2) + b2\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    #y1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, W1) + b1)\n",
    "    #valid_logits = tf.matmul(y1_valid, W2) + b2\n",
    "    #valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    w1=tf.cast(W1, tf.float64)\n",
    "    B1=tf.cast(b1, tf.float64)\n",
    "    w2=tf.cast(W2, tf.float64)\n",
    "    B2=tf.cast(b2, tf.float64)\n",
    "    y1_test = tf.nn.relu(tf.matmul(tf_test_dataset, w1) + B1)\n",
    "    test_logits = tf.matmul(y1_test, w2) + B2\n",
    "    test_prediction = tf.nn.softmax(test_logits)\n",
    "    y2_test = tf.nn.relu(tf.matmul(tf_test_dataset2, w1) + B1)\n",
    "    test_logits2 = tf.matmul(y2_test, w2) + B2\n",
    "    test_prediction2 = tf.nn.softmax(test_logits2)\n",
    "    print test_prediction2\n",
    "    print test_prediction\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f457eadadd0>\n"
     ]
    }
   ],
   "source": [
    "print graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeneratorContextManager' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f77e34abb3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3627\u001b[0m                        \"`eval(session=sess)`.\")\n\u001b[1;32m   3628\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneratorContextManager' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "#a=tf.Print(test_prediction,[test_prediction])\n",
    "#b = tf.add(a, a).eval(session=graph.as_default())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(175, 1024), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-67-44c113c2ce7f>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 0: 3099.464355\n",
      "Minibatch accuracy: 70.9%\n",
      "Test accuracy: 28.6%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 500: 0.416098\n",
      "Minibatch accuracy: 86.7%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 1000: 0.120458\n",
      "Minibatch accuracy: 100.0%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 1500: 0.141797\n",
      "Minibatch accuracy: 100.0%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 2000: 0.355552\n",
      "Minibatch accuracy: 88.8%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 2500: 0.118711\n",
      "Minibatch accuracy: 100.0%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "(1128, 13)\n",
      "(1128, 2)\n",
      "(1128, 2)\n",
      "Minibatch loss at step 3000: 0.571963\n",
      "Minibatch accuracy: 77.8%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "Test accuracy: 71.4%\n",
      "Test accuracy 2: 50.0%\n",
      "[[ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " ..., \n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]]\n",
      "[[ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]\n",
      " [ 0.87181889  0.12818111]]\n"
     ]
    }
   ],
   "source": [
    "# Let's run it:\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #saver = tf.train.Saver()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = tr_features[offset:(offset + batch_size), :]\n",
    "        batch_labels = tr_labels[offset:(offset + batch_size), :]\n",
    "        #print batch_labels\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print np.shape(batch_data)\n",
    "            print np.shape(predictions)           \n",
    "            print np.shape(batch_labels)\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            #print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "            print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), ts_labels))\n",
    "            print(\"Test accuracy 2: %.1f%%\" % accuracy(test_prediction2.eval(), single_labels))\n",
    "        #save_path = saver.save(session, \"model.ckpt\") #saves the cirrent model\n",
    "\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), ts_labels))\n",
    "    print(\"Test accuracy 2: %.1f%%\" % accuracy(test_prediction2.eval(), single_labels))    \n",
    "    check2=test_prediction2.eval()\n",
    "    print check2\n",
    "    check1=test_prediction.eval()\n",
    "    print check1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       ..., \n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111],\n",
       "       [ 0.87181889,  0.12818111]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /tmp/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/Assign/_2 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op u'save/RestoreV2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-54c911b5dc58>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /tmp/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/Assign/_2 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-54c911b5dc58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Restore variables from disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/tmp/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1388\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /tmp/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/Assign/_2 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op u'save/RestoreV2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-54c911b5dc58>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /tmp/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/Assign/_2 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "#new model to be loaad by tf.restore\n",
    "v1 = tf.Variable(11, name=\"v1\")\n",
    "v2 = tf.Variable(22, name=\"v2\")\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
